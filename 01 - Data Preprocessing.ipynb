{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac46950",
   "metadata": {},
   "source": [
    "# 01 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a734dd5",
   "metadata": {},
   "source": [
    "## A - Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5831400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaboDGD.util import data, train\n",
    "from metaboDGD.src import model\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributions as D\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b7d12d",
   "metadata": {},
   "source": [
    "## B - Retrieving Separate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "215cd58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, cohorts = data.combine_cohort_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d04e0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the df to a numpy array of dim (# samples, # metabolites)\n",
    "np_df = df.T.to_numpy()\n",
    "\n",
    "# Get cells that have a 0.0\n",
    "np_df_zm = (np_df == 0)\n",
    "\n",
    "# Exponentiate the df by 2\n",
    "np_exp = np.exp2(np_df)\n",
    "\n",
    "# Retain the 0.0 values\n",
    "np_exp[np_df_zm] = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "021763b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np_df[0]\n",
    "zero_mask = (sample == 0)\n",
    "nonzero_mask = ~(zero_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ce5a99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\AnacondaDestination\\Lib\\site-packages\\torch\\autograd\\__init__.py:251: UserWarning: Error detected in LogBackward0. Traceback of forward call that caused the error:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\AnacondaDestination\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\AnacondaDestination\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\AnacondaDestination\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\AnacondaDestination\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\AnacondaDestination\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\AnacondaDestination\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\AnacondaDestination\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\AnacondaDestination\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\AnacondaDestination\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 531, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\AnacondaDestination\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\AnacondaDestination\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\AnacondaDestination\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 775, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\AnacondaDestination\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\AnacondaDestination\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\AnacondaDestination\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\AnacondaDestination\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\AnacondaDestination\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\AnacondaDestination\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\AnacondaDestination\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\AnacondaDestination\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Alfonso Miguel Cruz\\AppData\\Local\\Temp\\ipykernel_45668\\890261055.py\", line 51, in <module>\n",
      "    dgd_model, train_rep, test_rep, history = train.train_dgd(\n",
      "  File \"c:\\Users\\Alfonso Miguel Cruz\\Desktop\\scDGD\\metaboDGD\\metaboDGD\\util\\train.py\", line 124, in train_dgd\n",
      "    recon_loss = dgd_model.dec.gamma_layer.loss(x, y).sum()\n",
      "  File \"c:\\Users\\Alfonso Miguel Cruz\\Desktop\\scDGD\\metaboDGD\\metaboDGD\\src\\decoder.py\", line 61, in loss\n",
      "    nll_nz = torch.log((1 - self.pi)) + self.logGammaDensity(x, y) - torch.log(1 - self.logGammaDensity(eps, y))\n",
      " (Triggered internally at C:\\Jenkins\\workspace\\IPEX-GPU-ARC770-Windows-Build\\frameworks.ai.pytorch.private-gpu\\torch\\csrc\\autograd\\python_anomaly_mode.cpp:119.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function 'LogBackward0' returned nan values in its 0th output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 51\u001b[0m\n\u001b[0;32m     39\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m     41\u001b[0m dgd_model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mMetaboDGD(\n\u001b[0;32m     42\u001b[0m     latent_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     43\u001b[0m     output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1915\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     cm_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiagonal\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     49\u001b[0m )\n\u001b[1;32m---> 51\u001b[0m dgd_model, train_rep, test_rep, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dgd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdgd_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdgd_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alfonso Miguel Cruz\\Desktop\\scDGD\\metaboDGD\\metaboDGD\\util\\train.py:130\u001b[0m, in \u001b[0;36mtrain_dgd\u001b[1;34m(dgd_model, train_loader, validation_loader, n_epochs, export_dir, export_name, lr_schedule_epochs, lr_schedule, optim_betas, wd, acc_save_threshold)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;66;03m# print(dist_loss)\u001b[39;00m\n\u001b[0;32m    128\u001b[0m     loss \u001b[38;5;241m=\u001b[39m recon_loss\u001b[38;5;241m.\u001b[39mclone() \u001b[38;5;241m+\u001b[39m dist_loss\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m--> 130\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[0;32m    132\u001b[0m gmm_optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\AnacondaDestination\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\AnacondaDestination\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Function 'LogBackward0' returned nan values in its 0th output."
     ]
    }
   ],
   "source": [
    "## TODO: Transfer to 02-Training\n",
    "class MetaboliteDataset(Dataset):\n",
    "    def __init__(self, np_mat):\n",
    "        # Instantiate Dataset object\n",
    "        # Initialize Directory containing data, annotations, transforms\n",
    "        self.metabolite_abundances = np_mat\n",
    "        # self.metabolite_abundances = self.metabolite_abundances.to(torch.float32)\n",
    "        self.n_metabolites = self.metabolite_abundances.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.metabolite_abundances.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.metabolite_abundances[idx], idx\n",
    "\n",
    "\n",
    "train_dict = {}\n",
    "test_dict  = {}\n",
    "\n",
    "# Split each cohort to train and test\n",
    "for c in cohorts.keys():\n",
    "    # Get Sample IDs for training and testing\n",
    "    _train, _test = train_test_split(cohorts[c]['sample_list'],\n",
    "                     train_size=0.8,\n",
    "                     random_state=100)\n",
    "    train_dict[c] = df.T.loc[_train].to_numpy()\n",
    "    test_dict[c] = df.T.loc[_test].to_numpy()\n",
    "\n",
    "\n",
    "# Combine the dataframes together\n",
    "train_df = np.vstack(list(train_dict.values()))\n",
    "test_df  = np.vstack(list(test_dict.values()))\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "train_dataset = MetaboliteDataset(train_df)\n",
    "test_dataset = MetaboliteDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "dgd_model = model.MetaboDGD(\n",
    "    latent_dim=20,\n",
    "    output_dim=1915,\n",
    "    dec_hidden_layers_dim=[475, 950, 1425],\n",
    "    dec_output_prediction_type='mean',\n",
    "    dec_output_activation_type='softplus',\n",
    "    n_comp=8,\n",
    "    cm_type='diagonal'\n",
    ")\n",
    "\n",
    "dgd_model, train_rep, test_rep, history = train.train_dgd(\n",
    "    dgd_model=dgd_model,\n",
    "    train_loader=train_loader,\n",
    "    validation_loader=test_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883658e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros_like(torch.randn((10,10))).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e3f7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = torch.rand((10,))\n",
    "# # test[5] = 0.0\n",
    "# # test[~(test == 0)] = 999.99\n",
    "# # test\n",
    "# torch.zeros_like(test)\n",
    "# torch.exp(gamma_dist.log_prob(torch.full(fill_value=1e-5, size=(1,10))))\n",
    "\n",
    "# gamma_dist = D.Gamma(torch.full(fill_value=3.0, size=(1,)),\n",
    "#                      torch.full(fill_value=1.0, size=(1,)))\n",
    "# plt.hist(gamma_dist.sample(sample_shape=(50000,)).squeeze().numpy(), bins=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08503e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.split(torch.Tensor(np_df), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a35dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count(np_exp.var(axis=0) > np_exp.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8464bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT REMOVE\n",
    "zero_counts = np.count_nonzero(np_exp == 0, axis=0)\n",
    "plt.scatter(x=np_exp.mean(axis=0),\n",
    "            y=np_exp.var(axis=0),\n",
    "            c=zero_counts,\n",
    "            cmap='viridis',\n",
    "            marker='o',\n",
    "            alpha=0.5)\n",
    "plt.xlabel(\"Mean Metabolite Abundance (Log 2 Scale)\")\n",
    "plt.ylabel(\"Variance Metabolite Abundance (Log 2 Scale)\")\n",
    "plt.xscale('log', base=2)\n",
    "plt.yscale('log', base=2)\n",
    "plt.colorbar(label='Number of Zeroes')\n",
    "plt.title(\"Mean-Variance Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26728aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(np_df == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce5edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT REMOVE\n",
    "plt.hist(\n",
    "    np_exp[:,100],\n",
    ")\n",
    "plt.title(\"Histogram of Processed Metabolite Abundances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6255492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BRCA1 ccRCC3  ccRCC4  COAD    GBM HurthleCC   PDAC    PRAD\n",
    "target_cohort = \"BRCA1\"\n",
    "START_IDX = len(cohorts[\"ccRCC3\"]['sample_list']) * 0\n",
    "END_IDX = len(cohorts[target_cohort]['sample_list'])\n",
    "cohort_df = np_df[START_IDX:START_IDX+END_IDX]\n",
    "zero_counts = np.count_nonzero(cohort_df == 0, axis=0)\n",
    "\n",
    "plt.scatter(x=cohort_df.mean(axis=0),\n",
    "            y=cohort_df.var(axis=0),\n",
    "            c=zero_counts,\n",
    "            cmap='viridis',\n",
    "            marker='o',\n",
    "            alpha=0.3)\n",
    "plt.xlabel(\"Mean Metabolite Abundance (Log 2)\")\n",
    "plt.ylabel(\"Variance Metabolite Abundance (Log 2)\")\n",
    "plt.title(target_cohort)\n",
    "plt.colorbar(label='Number of Zeroes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f59a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the indices of the 26 metabolites present across all samples (26)\n",
    "# set([x for x in range(0,1915)]) - set(np.unique(np.where(np_df == 0)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285808d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "np_df = df.T.to_numpy()\n",
    "pca_model = PCA(n_components=2)\n",
    "results = pca_model.fit_transform(np_df)\n",
    "\n",
    "plt.scatter(results[0:47,0], results[0:47, 1], c='red'          ,label=\"BRCA1\")\n",
    "plt.scatter(results[47:86,0], results[47:86, 1], c='orange'     ,label=\"COAD\")\n",
    "plt.scatter(results[86:133,0], results[86:133, 1], c='yellow'   ,label=\"ccRCC3\")\n",
    "plt.scatter(results[133:157,0], results[133:157, 1], c='green'  ,label=\"ccRCC4\")\n",
    "plt.scatter(results[157:163,0], results[157:163, 1], c='blue'   ,label=\"GBM\")\n",
    "plt.scatter(results[163:166,0], results[163:166, 1], c='purple' ,label=\"HurthleCC\")\n",
    "plt.scatter(results[166:178,0], results[166:178, 1], c='pink'   ,label=\"PDAC\")\n",
    "plt.scatter(results[178:224,0], results[178:224, 1], c='black'  ,label=\"PRAD\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b47e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmm = GaussianMixture(n_components=8)\n",
    "gmm = gmm.fit(np_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = gmm.sample(n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b06b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.Series(results[1]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f462fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_new = PCA(n_components=2)\n",
    "results_new = pca_model.transform(results[0])\n",
    "# results_new = pca_model.transform(results[0])\n",
    "# plt.scatter(results_new[0:224,0]   , results_new[0:224, 1], c='red'          ,label=\"BRCA1\")\n",
    "# plt.scatter(results_new[224:426,0]  , results_new[224:426, 1], c='orange'     ,label=\"COAD\")\n",
    "# plt.scatter(results_new[426:609,0] , results_new[426:609, 1], c='yellow'   ,label=\"ccRCC3\")\n",
    "# plt.scatter(results_new[609:785,0], results_new[609:785, 1], c='green'  ,label=\"ccRCC4\")\n",
    "# plt.scatter(results_new[785:903,0], results_new[785:903, 1], c='blue'   ,label=\"GBM\")\n",
    "# plt.scatter(results_new[903:956,0], results_new[903:956, 1], c='purple' ,label=\"HurthleCC\")\n",
    "# plt.scatter(results_new[956:983,0], results_new[956:983, 1], c='pink'   ,label=\"PDAC\")\n",
    "plt.scatter(results_new[983:1000,0], results_new[983:1000, 1], c='black'  ,label=\"PRAD\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ec83a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_new = PCA(n_components=2)\n",
    "results_new = pca_model.transform(results[0])\n",
    "# plt.scatter(results_new[0:47,0]   , results_new[0:47, 1], c='red'          ,label=\"BRCA1\")\n",
    "# plt.scatter(results_new[47:86,0]  , results_new[47:86, 1], c='orange'     ,label=\"COAD\")\n",
    "# plt.scatter(results_new[86:133,0] , results_new[86:133, 1], c='yellow'   ,label=\"ccRCC3\")\n",
    "# plt.scatter(results_new[133:157,0], results_new[133:157, 1], c='green'  ,label=\"ccRCC4\")\n",
    "# plt.scatter(results_new[157:163,0], results_new[157:163, 1], c='blue'   ,label=\"GBM\")\n",
    "# plt.scatter(results_new[163:166,0], results_new[163:166, 1], c='purple' ,label=\"HurthleCC\")\n",
    "# plt.scatter(results_new[166:178,0], results_new[166:178, 1], c='pink'   ,label=\"PDAC\")\n",
    "# plt.scatter(results_new[178:224,0], results_new[178:224, 1], c='black'  ,label=\"PRAD\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1d9e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the xls file\n",
    "cohort_name = \"PRAD\"\n",
    "xls = pd.ExcelFile(f'data/PreprocessedData_{cohort_name}.xlsx')\n",
    "\n",
    "# Get the dataframes for the preprocessed metabolomics data\n",
    "# t = xls.parse(\"metabo_imputed_filtered_Tumor\")\n",
    "n = xls.parse(\"metabo_imputed_filtered_Normal\")\n",
    "\n",
    "# Replace IDs of the dataframes\n",
    "# t.rename({\"Unnamed: 0\": \"t_met\"}, inplace=True, axis=1)\n",
    "n.rename({\"Unnamed: 0\": \"n_met\"}, inplace=True, axis=1)\n",
    "\n",
    "# Get list of metabolites\n",
    "# t_list = t[\"t_met\"].to_list()\n",
    "n_list = n[\"n_met\"].to_list()\n",
    "# met_list = list(set(t_list) | set(n_list))\n",
    "\n",
    "# Create a dictionary of the metabolite names and HMDB IDs\n",
    "###########\n",
    "# 05/25/25 - Eliminated HMDB IDs use because only 72% of the features have HMDB IDs across all cohorts\n",
    "# For Reference:\n",
    "#           TOTAL_FEATURES  TOTAL_FEATURES_WITH_HMDB_IDS\n",
    "# BRCA1     324             215\n",
    "# COAD      160\t            141\n",
    "# ccRCC3    727\t            551\n",
    "# ccRCC4    951\t            701\n",
    "# GBM       704\t            357\n",
    "# HurthleCC 668\t            523\n",
    "# PDAC      325\t            279\n",
    "# PRAD      382\t            320\n",
    "###########\n",
    "# metanno = xls.parse(\"metanno\")\n",
    "# metanno_dict = metanno.set_index(\"H_name\")[\"H_HMDB\"].to_dict()\n",
    "# hmdb_list = set(metanno.loc[metanno[\"H_name\"].isin(n_list)][\"H_HMDB\"].tolist()\n",
    "\n",
    "\n",
    "# Get dataframe with only sorted shared metabolites\n",
    "# t_shared = t[t[\"t_met\"].isin(met_list)]\n",
    "# t_shared.sort_values(\"t_met\", ignore_index=True, inplace=True)\n",
    "# n_shared = n[n[\"n_met\"].isin(met_list)]\n",
    "# n_shared.sort_values(\"n_met\", ignore_index=True, inplace=True)\n",
    "# merged = pd.concat([t_shared, n_shared], axis=1)\n",
    "\n",
    "# n = n.set_index(n[\"n_met\"])\n",
    "n_no_labels = n.drop(labels=['n_met'], axis=1)\n",
    "print(n.set_index(\"n_met\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
